{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./data/cifar_test_nolabel.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "\n",
    "    class CustomDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, data, transform=None):\n",
    "            self.data = data\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.data[idx]\n",
    "            label = 0\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "\n",
    "    transform_test = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ]\n",
    "    )\n",
    "    custom_testset = CustomDataset(data[b\"data\"], transform=transform_test)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        custom_testset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "\n",
    "    return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(args):\n",
    "\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"device: {device}\")\n",
    "\n",
    "    print(\"==> build model...\")\n",
    "    net = Resnet_Leaky()\n",
    "    net = net.to(device)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    print(f\"==> load {args.checkpoint}...\")\n",
    "    checkpoint = torch.load(args.checkpoint)\n",
    "\n",
    "    if \"net\" in checkpoint:\n",
    "        state_dict = checkpoint[\"net\"]\n",
    "        from collections import OrderedDict\n",
    "\n",
    "        new_state_dict = OrderedDict()\n",
    "        if all(k.startswith(\"module.\") for k in state_dict.keys()) and not all(\n",
    "            k.startswith(\"module.\") for k in net.state_dict().keys()\n",
    "        ):\n",
    "            for k, v in state_dict.items():\n",
    "                name = k[7:]  \n",
    "                new_state_dict[name] = v\n",
    "        elif not all(k.startswith(\"module.\") for k in state_dict.keys()) and all(\n",
    "            k.startswith(\"module.\") for k in net.state_dict().keys()\n",
    "        ):\n",
    "            for k, v in state_dict.items():\n",
    "                name = \"module.\" + k\n",
    "                new_state_dict[name] = v\n",
    "        else:\n",
    "            new_state_dict = state_dict\n",
    "\n",
    "        try:\n",
    "            net.load_state_dict(new_state_dict, strict=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"load fail: {e}\")\n",
    "            print(\"trial...\")\n",
    "\n",
    "            print(\"model key:\")\n",
    "            model_keys = set(net.state_dict().keys())\n",
    "            print(f\"total: {len(model_keys)}\")\n",
    "            print(\"keys:\", list(model_keys)[:5])\n",
    "\n",
    "            print(\"Checkpoint key:\")\n",
    "            ckpt_keys = set(state_dict.keys())\n",
    "            print(f\"total: {len(ckpt_keys)}\")\n",
    "            print(\"keys:\", list(ckpt_keys)[:5])\n",
    "\n",
    "            compatible_state_dict = {}\n",
    "            for model_key in model_keys:\n",
    "                possible_keys = [\n",
    "                    model_key,\n",
    "                    model_key.replace(\"module.\", \"\"),\n",
    "                    \"module.\" + model_key,\n",
    "                ]\n",
    "\n",
    "                for key in possible_keys:\n",
    "                    if key in ckpt_keys:\n",
    "                        compatible_state_dict[model_key] = state_dict[key]\n",
    "                        break\n",
    "\n",
    "            if compatible_state_dict:\n",
    "                net.load_state_dict(compatible_state_dict, strict=False)\n",
    "                print(\n",
    "                    f\"load {len(compatible_state_dict)}/{len(model_keys)} weights\"\n",
    "                )\n",
    "            else:\n",
    "                print(\"fail\")\n",
    "\n",
    "        best_acc = checkpoint.get(\"acc\", 0)\n",
    "        epoch = checkpoint.get(\"epoch\", 0)\n",
    "        print(f\"load, best accuracy: {best_acc:.2f}%, epoch: {epoch}\")\n",
    "\n",
    "    return net, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(args):\n",
    "    testloader = load_data(args)\n",
    "    net, device = load_checkpoint(args)\n",
    "    net.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_sample_indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, _) in enumerate(testloader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                sample_idx = batch_idx * testloader.batch_size + i\n",
    "                all_sample_indices.append(sample_idx)\n",
    "                all_predictions.append(predicted[i].item())\n",
    "\n",
    "            progress_bar(\n",
    "                batch_idx,\n",
    "                len(testloader),\n",
    "                \"Processing: %d/%d\"\n",
    "                % (\n",
    "                    batch_idx + 1,\n",
    "                    len(testloader),\n",
    "                ),\n",
    "            )\n",
    "    import csv\n",
    "\n",
    "    with open(\"prediction_results.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"ID\", \"Labels\"])\n",
    "        for idx, pred in zip(all_sample_indices, all_predictions):\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    idx,\n",
    "                    pred,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    print(\"Results saved to prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "==> build model...\n",
      "==> load ./checkpoint/ckpt9549_leaky1.pth...\n",
      "load, best accuracy: 95.49%, epoch: 237\n",
      " [================================================================>]  Step: 262ms | Tot: 1s644ms | Processing: 79/ 79/79 =================================>............................]  Step: 22ms | Tot: 760ms | Processing: 45/ 45/79 \n",
      "Results saved to prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.num_workers = 0\n",
    "        self.checkpoint = r\"./checkpoint/ckpt9549_leaky1.pth\"\n",
    "\n",
    "\n",
    "args = args()\n",
    "test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
